{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNzEAThUsG7ZfOCk3He9oBv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utkarshmishra2k2/Focus_on_Vision-A_Statistical_Study_of_Eye/blob/main/Focus_on_Vision_A_Statistical_Study_of_Eye.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from collections import Counter\n",
        "\n",
        "# Data Preprocessing and Transformation\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Statistical Analysis and Feature Selection\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Machine Learning and Deep Learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Model Evaluation\n",
        "from sklearn.metrics import log_loss, accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc"
      ],
      "metadata": {
        "id": "mRSJDSxWS_nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01 = pd.read_excel('https://raw.githubusercontent.com/Utkarshmishra2k2/Focus_on_Vision-A_Statistical_Study_of_Eye/refs/heads/main/DATA:Focus%20on%20Vision_%20A%20Statistical%20Study%20of%20Eye.xlsx')"
      ],
      "metadata": {
        "id": "ItqyBiyxTAz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "kaefXtAcTT9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = {\n",
        "    \"1\": \"age\",\n",
        "    \"2\": \"gender\",\n",
        "    \"3\": \"occupation\",\n",
        "    \"4\": \"education\",\n",
        "    \"5\": \"environment\",\n",
        "    \"6\": \"screen_hours\",\n",
        "    \"7\": \"device\",\n",
        "    \"8\": \"screen_use_purpose\",\n",
        "    \"9\": \"screen_symptoms\",\n",
        "    \"10\": \"reading_medium\",\n",
        "    \"11\": \"reading_hours\",\n",
        "    \"12\": \"night_mode\",\n",
        "    \"13\": \"theme_usage\",\n",
        "    \"14\": \"dark_usage\",\n",
        "    \"15\": \"blue_light_usage\",\n",
        "    \"16\": \"outdoor_activity\",\n",
        "    \"17\": \"sunlight_hours\",\n",
        "    \"18\": \"exercise_frequency\",\n",
        "    \"19\": \"wear_sunglasses\",\n",
        "    \"20\": \"lighting_conditions\",\n",
        "    \"21\": \"take_breaks\",\n",
        "    \"22\": \"sleep_hours\",\n",
        "    \"23\": \"device_before_bedtime\",\n",
        "    \"24\": \"eye_strain_reduction\",\n",
        "    \"25\": \"nutrient_intake\",\n",
        "    \"26\": \"air_quality\",\n",
        "    \"27\": \"smoking_status\",\n",
        "    \"28\": \"vision_correction\",\n",
        "    \"29\": \"age_vision_correction\",\n",
        "    \"30\": \"left_eye_power\",\n",
        "    \"31\": \"right_eye_power\",\n",
        "    \"32\": \"reason_vision_correction\",\n",
        "    \"33\": \"screen_fatigue\",\n",
        "    \"34\": \"activity_duration\",\n",
        "    \"35\": \"eye_checkup_frequency\",\n",
        "    \"36\": \"eye_self_care\",\n",
        "    \"37\": \"future_vision_correction\",\n",
        "    \"38\": \"corrective_procedures\",\n",
        "    \"39\": \"surgical_procedure\",\n",
        "    \"40\": \"surgery_age\",\n",
        "    \"41\": \"procedure_effectiveness\",\n",
        "    \"42\": \"parents_vision_problems\",\n",
        "    \"43\": \"parent_with_vision_issues\",\n",
        "    \"44\": \"parent_tools\",\n",
        "    \"45\": \"parent_vision_problems\",\n",
        "    \"46\": \"father_age_vision_correction\",\n",
        "    \"47\": \"mother_age_vision_correction\",\n",
        "    \"48\": \"relatives_vision_problems\",\n",
        "    \"49\": \"relative_with_vision_issues\",\n",
        "    \"50\": \"relative_tools\",\n",
        "    \"51\": \"relative_vision_problems\",\n",
        "    \"52\": \"relative_age_vision_correction\",\n",
        "    \"53\": \"offspring_vision_problems\",\n",
        "    \"54\": \"offspring_vision_problems_type\",\n",
        "    \"55\": \"offspring_diagnosis_age\",\n",
        "    \"56\": \"offspring_using_correction_tools\",\n",
        "    \"57\": \"offspring_screen_time\",\n",
        "    \"58\": \"offspring_outdoor_time\",\n",
        "    \"59\": \"vision_influence_on_children\",\n",
        "    \"60\": \"steps_to_prevent_children_vision\",\n",
        "    \"61\": \"district\"\n",
        "}"
      ],
      "metadata": {
        "id": "ShSBN3OgTQQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01.columns = data_01.columns.str.strip()\n",
        "data_01.rename(columns=columns, inplace=True)"
      ],
      "metadata": {
        "id": "INpxgKmvTVe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01.dtypes"
      ],
      "metadata": {
        "id": "PDczyEm2TXJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01.isnull().sum()"
      ],
      "metadata": {
        "id": "kvYHTpTqTYhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(data_01.isnull().sum() / len(data_01)) * 100"
      ],
      "metadata": {
        "id": "IATbgAixTaK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01.describe(include='all').T"
      ],
      "metadata": {
        "id": "Pa8JCJ0cTbg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01.info()"
      ],
      "metadata": {
        "id": "9gTPlPVgTdEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def has_glasses(row):\n",
        "    vc = row.get(\"vision_correction\")\n",
        "    print(f\"Processing row: vision_correction = {vc}, left_eye_power = {row.get('left_eye_power')}, right_eye_power = {row.get('right_eye_power')}, age_vision_correction = {row.get('age_vision_correction')}\")\n",
        "    left_power = row.get(\"left_eye_power\")\n",
        "    right_power = row.get(\"right_eye_power\")\n",
        "    if (pd.isnull(left_power) or left_power == 0) and (pd.isnull(right_power) or right_power == 0):\n",
        "        return \"No\"\n",
        "    if pd.notnull(left_power) and left_power != 0:\n",
        "        return \"Yes\"\n",
        "    if pd.notnull(right_power) and right_power != 0:\n",
        "        return \"Yes\"\n",
        "    if pd.notnull(row.get(\"age_vision_correction\")) and vc in [\"Glasses\", \"Contact Lenses\",\"Surgical Correction\",'Vision Therapy']:\n",
        "        return \"Yes\"\n",
        "    return \"No\"\n",
        "data_01[\"has_or_had_glasses\"] = data_01.apply(has_glasses, axis=1)\n",
        "print(data_01[[\"vision_correction\", \"left_eye_power\", \"right_eye_power\", \"age_vision_correction\", \"has_or_had_glasses\"]].head())\n",
        "print(data_01[\"has_or_had_glasses\"].value_counts())"
      ],
      "metadata": {
        "id": "JyPVd44ATi52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_01['has_or_had_glasses'].value_counts())"
      ],
      "metadata": {
        "id": "UuQQGzC3Tku4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_missing_cols = data_01.columns[data_01.isnull().all()]"
      ],
      "metadata": {
        "id": "4pCmJerhTnOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped = data_01.drop(all_missing_cols, axis=1)"
      ],
      "metadata": {
        "id": "qeNwNUDnTo1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01.drop(['air_quality'], axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "ruWtVhReTqIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_cols = df_dropped.select_dtypes(include=['number']).columns\n",
        "categorical_cols = df_dropped.select_dtypes(exclude=['number']).columns"
      ],
      "metadata": {
        "id": "p30zebjBTr7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_imputer = SimpleImputer(strategy='median')\n",
        "categorical_imputer = SimpleImputer(strategy='most_frequent')"
      ],
      "metadata": {
        "id": "oIcYfC99TtWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_imputed = df_dropped.copy()\n",
        "df_imputed[numerical_cols] = numerical_imputer.fit_transform(df_dropped[numerical_cols])\n",
        "df_imputed[categorical_cols] = categorical_imputer.fit_transform(df_dropped[categorical_cols])"
      ],
      "metadata": {
        "id": "wFipcA3BTuj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01 = df_imputed.copy()"
      ],
      "metadata": {
        "id": "Fz6aBSbjTv0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = data_01.select_dtypes(include=['category', 'object']).columns\n",
        "numerical_columns = data_01.select_dtypes(include=['number']).columns"
      ],
      "metadata": {
        "id": "Vuor2V5mTw-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01[categorical_columns] = data_01[categorical_columns].apply(lambda x: x.astype('category'))"
      ],
      "metadata": {
        "id": "jYTwx4JHTyfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numerical_columns:\n",
        "    data_01[col] = pd.to_numeric(data_01[col], errors='coerce')"
      ],
      "metadata": {
        "id": "hIjkzHpETz14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aqi_dict = {\n",
        "    'Dombivali': 59,\n",
        "    'Ghatkopar': 102,\n",
        "    'Kurla':102,\n",
        "    'Bhandup': 106,\n",
        "    'Mumbai Suburban': 102,\n",
        "    'Thane': 79,\n",
        "    'Palghar': 89,\n",
        "    'Mumbai': 85,\n",
        "    'Vasai': 72,\n",
        "    'Virar': 71,\n",
        "    'Kalyan': 93\n",
        "}"
      ],
      "metadata": {
        "id": "5u9ehaZ_T1A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01['air_quality'] = data_01['district'].astype(str).str.strip().map(aqi_dict)\n",
        "data_01['air_quality'] = pd.to_numeric(data_01['air_quality'], errors='coerce')"
      ],
      "metadata": {
        "id": "Xp2vVwHKT2mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistical Analysis"
      ],
      "metadata": {
        "id": "S3QFFUrkUEZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normality_tests(data_01, numeric_columns):\n",
        "    \"\"\"\n",
        "    Perform multiple normality tests on the numeric columns of a dataset.\n",
        "\n",
        "    This function applies three statistical tests for normality to each numeric column in the\n",
        "    input DataFrame `data_01`. It calculates the following tests:\n",
        "    1. Shapiro-Wilk Test\n",
        "    2. Kolmogorov-Smirnov (KS) Test\n",
        "    3. Anderson-Darling Test\n",
        "\n",
        "    For each test, the function computes the test statistic and p-value (where applicable).\n",
        "    The results of these tests are stored in a list of dictionaries and then returned as\n",
        "    a pandas DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    data_01 : pandas.DataFrame\n",
        "        The DataFrame containing the data. It must have numeric columns that you want to test for normality.\n",
        "\n",
        "    numeric_columns : list\n",
        "        A list of column names (strings) in the DataFrame `data_01` that are numeric and should be tested for normality.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    pandas.DataFrame\n",
        "        A DataFrame containing the results of the normality tests for each numeric column.\n",
        "        The DataFrame includes the following columns:\n",
        "        - 'Column': Name of the column.\n",
        "        - 'Shapiro-Wilk Statistic': The test statistic for the Shapiro-Wilk test.\n",
        "        - 'Shapiro-Wilk p-value': The p-value for the Shapiro-Wilk test.\n",
        "        - 'KS Statistic': The test statistic for the Kolmogorov-Smirnov test.\n",
        "        - 'KS p-value': The p-value for the Kolmogorov-Smirnov test.\n",
        "        - 'Anderson-Darling Statistic': The test statistic for the Anderson-Darling test.\n",
        "        - 'Anderson-Darling Critical Values': The critical values from the Anderson-Darling test.\n",
        "        - 'Anderson-Darling Significance Levels': The significance levels for the Anderson-Darling test.\n",
        "\n",
        "    Example:\n",
        "    --------\n",
        "    normality_df = normality_tests(data_01, ['col1', 'col2', 'col3'])\n",
        "\n",
        "    This will apply the three normality tests to the columns 'col1', 'col2', and 'col3'\n",
        "    of the DataFrame `data_01` and return the results in `normality_df`.\n",
        "    \"\"\"\n",
        "\n",
        "    normality_results = []\n",
        "    for col in numeric_columns:\n",
        "        shapiro_stat, shapiro_p = stats.shapiro(data_01[col].dropna())\n",
        "        ks_stat, ks_p = stats.kstest(data_01[col].dropna(), 'norm', args=(data_01[col].mean(), data_01[col].std()))\n",
        "        anderson_result = stats.anderson(data_01[col].dropna(), dist='norm')\n",
        "        normality_results.append({\n",
        "            'Column': col,\n",
        "            'Shapiro-Wilk Statistic': shapiro_stat,\n",
        "            'Shapiro-Wilk p-value': shapiro_p,\n",
        "            'KS Statistic': ks_stat,\n",
        "            'KS p-value': ks_p,\n",
        "            'Anderson-Darling Statistic': anderson_result.statistic,\n",
        "            'Anderson-Darling Critical Values': anderson_result.critical_values,\n",
        "            'Anderson-Darling Significance Levels': anderson_result.significance_level\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(normality_results)\n",
        "normality_tests(data_01, numerical_columns)"
      ],
      "metadata": {
        "id": "TXntIO0gUA_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(rows=7, cols=5, subplot_titles=numerical_columns) # Changed rows and cols\n",
        "for i, col in enumerate(numerical_columns):\n",
        "    data = data_01[col].dropna()\n",
        "    (theoretical_q, sample_q), _ = stats.probplot(data, dist=\"norm\")\n",
        "    row = i // 5 + 1\n",
        "    col_index = i % 5 + 1\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=theoretical_q,\n",
        "            y=sample_q,\n",
        "            mode='markers',\n",
        "            name=col,\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=row, col=col_index\n",
        "    )\n",
        "    min_val = min(theoretical_q.min(), sample_q.min())\n",
        "    max_val = max(theoretical_q.max(), sample_q.max())\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=[min_val, max_val],\n",
        "            y=[min_val, max_val],\n",
        "            mode='lines',\n",
        "            line=dict(color='red', dash='dash'),\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=row, col=col_index\n",
        "    )\n",
        "\n",
        "fig.update_layout(height=2500, width=1200, title_text=\"Q-Q Plots\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "FEp-FGpGUF-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normality = normality_tests(data_01, numerical_columns)\n",
        "# normality.to_csv('normality.csv', index=False)"
      ],
      "metadata": {
        "id": "CyhkN7JEUHhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spearman_correlation(data_01, numeric_columns):\n",
        "    \"\"\"\n",
        "    Calculate Spearman's rank correlation for each pair of numeric columns in the dataset.\n",
        "\n",
        "    This function calculates the Spearman's rank correlation coefficient for each pair\n",
        "    of numeric columns in the input DataFrame `data_01`. It computes both the correlation coefficient\n",
        "    and the associated p-value for each pair.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    data_01 : pandas.DataFrame\n",
        "        The DataFrame containing the data. It must have numeric columns for correlation calculation.\n",
        "\n",
        "    numeric_columns : list\n",
        "        A list of column names (strings) in the DataFrame `data_01` that are numeric and should be used for\n",
        "        Spearman's rank correlation.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    pandas.DataFrame\n",
        "        A DataFrame containing the results of the Spearman correlation tests for each pair of numeric columns.\n",
        "        The DataFrame includes the following columns:\n",
        "        - 'Column 1': Name of the first column in the pair.\n",
        "        - 'Column 2': Name of the second column in the pair.\n",
        "        - 'Spearman Correlation Coefficient': The Spearman correlation coefficient between the two columns.\n",
        "        - 'Spearman p-value': The p-value associated with the Spearman correlation coefficient.\n",
        "\n",
        "    Example:\n",
        "    --------\n",
        "    correlation_df = spearman_correlation(data_01, ['col1', 'col2', 'col3'])\n",
        "\n",
        "    This will compute the Spearman's rank correlation for all pairs of columns 'col1', 'col2', and 'col3'\n",
        "    in the DataFrame `data_01` and return the results in `correlation_df`.\n",
        "    \"\"\"\n",
        "\n",
        "    correlation_results = []\n",
        "\n",
        "    for i, col1 in enumerate(numeric_columns):\n",
        "        for col2 in numeric_columns[i+1:]:\n",
        "            spearman_corr, spearman_p = stats.spearmanr(data_01[col1].dropna(), data_01[col2].dropna())\n",
        "\n",
        "            correlation_results.append({\n",
        "                'Column 1': col1,\n",
        "                'Column 2': col2,\n",
        "                'Spearman Correlation Coefficient': spearman_corr,\n",
        "                'Spearman p-value': spearman_p\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(correlation_results)\n",
        "spearman_correlation(data_01, numerical_columns)"
      ],
      "metadata": {
        "id": "tloy-dKwULLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_spearman_correlation_matrix_seaborn(data_01, numeric_columns):\n",
        "    \"\"\"\n",
        "    Plot the Spearman correlation matrix as a heatmap using Seaborn and Matplotlib.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    data_01 : pandas.DataFrame\n",
        "        The DataFrame containing the data. It must have numeric columns for correlation calculation.\n",
        "\n",
        "    numeric_columns : list\n",
        "        A list of column names (strings) in the DataFrame `data_01` that are numeric and should be used for\n",
        "        Spearman's rank correlation.\n",
        "    \"\"\"\n",
        "    spearman_corr_matrix = data_01[numeric_columns].corr(method='spearman')\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(spearman_corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5, cbar=True, facecolor='white')\n",
        "    plt.title('Spearman Correlation Matrix')\n",
        "    plt.gca().set_facecolor('grey')  # Set the axes background color to white\n",
        "    plt.gcf().set_facecolor('grey')  # Set the figure background color to white\n",
        "    plt.show()\n",
        "\n",
        "plot_spearman_correlation_matrix_seaborn(data_01, numerical_columns)"
      ],
      "metadata": {
        "id": "AVd7SRq2US9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation = spearman_correlation(data_01, numerical_columns)\n",
        "# correlation.to_csv('correlation.csv', index=False)"
      ],
      "metadata": {
        "id": "dBO5Y13WULiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crosstab Analysis with Chi-Square Test\n",
        "def chi_square_crosstab(data_01, categorical_columns):\n",
        "    \"\"\"\n",
        "    Perform Chi-Square Test of Independence between each pair of categorical variables in the dataset.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    data_01 : pandas.DataFrame\n",
        "        The DataFrame containing the data. It must include categorical columns to be tested.\n",
        "\n",
        "    categorical_columns : list of str\n",
        "        A list of column names (strings) representing categorical columns to be tested.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    pandas.DataFrame\n",
        "        A DataFrame containing the results of the Chi-Square Test of Independence for each pair of categorical variables.\n",
        "        The DataFrame includes the following columns:\n",
        "        - 'Categorical Variable 1': The first categorical variable in the pair.\n",
        "        - 'Categorical Variable 2': The second categorical variable in the pair.\n",
        "        - 'Chi-Square Statistic': The Chi-Square test statistic.\n",
        "        - 'p-value': The p-value for the Chi-Square test.\n",
        "        - 'Degrees of Freedom': The degrees of freedom for the Chi-Square test.\n",
        "    \"\"\"\n",
        "\n",
        "    chi_square_results = []\n",
        "\n",
        "    for i, var1 in enumerate(categorical_columns):\n",
        "        for var2 in categorical_columns[i + 1:]:\n",
        "            contingency_table = pd.crosstab(data_01[var1], data_01[var2])\n",
        "\n",
        "            chi2_stat, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "            chi_square_results.append({\n",
        "                'Categorical Variable 1': var1,\n",
        "                'Categorical Variable 2': var2,\n",
        "                'Chi-Square Statistic': chi2_stat,\n",
        "                'p-value': p_value,\n",
        "                'Degrees of Freedom': dof\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(chi_square_results)\n",
        "chi_square_crosstab(data_01, categorical_columns)"
      ],
      "metadata": {
        "id": "WMdhIXXfUeOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# crosstab = chi_square_crosstab(data_01, categorical_columns)\n",
        "# crosstab.to_csv('crosstab.csv', index=False)"
      ],
      "metadata": {
        "id": "GArt0rm-Uekp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chi_square_independence(data_01, categorical_columns):\n",
        "    \"\"\"\n",
        "    Perform Chi-Square Test for Independence between pairs of categorical columns.\n",
        "\n",
        "    This function calculates the Chi-Square Test for Independence for each pair of categorical columns in the\n",
        "    input DataFrame `data_01`. It computes the Chi-Square statistic, p-value, degrees of freedom,\n",
        "    and the expected frequency table for each pair.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    data_01 : pandas.DataFrame\n",
        "        The DataFrame containing the data. It must have categorical columns for the Chi-Square test.\n",
        "\n",
        "    categorical_columns : list\n",
        "        A list of column names (strings) in the DataFrame `data_01` that are categorical and should be used for\n",
        "        the Chi-Square Test for Independence.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    pandas.DataFrame\n",
        "        A DataFrame containing the results of the Chi-Square Test for Independence for each pair of categorical columns.\n",
        "        The DataFrame includes the following columns:\n",
        "        - 'Column 1': Name of the first column in the pair.\n",
        "        - 'Column 2': Name of the second column in the pair.\n",
        "        - 'Chi-Square Statistic': The Chi-Square statistic for the test.\n",
        "        - 'p-value': The p-value associated with the Chi-Square test.\n",
        "        - 'Degrees of Freedom': The degrees of freedom for the test.\n",
        "        - 'Expected Frequencies': The expected frequencies under the null hypothesis of independence.\n",
        "\n",
        "    Example:\n",
        "    --------\n",
        "    chi_square_df = chi_square_independence(data_01, ['col1', 'col2', 'col3'])\n",
        "\n",
        "    This will compute the Chi-Square Test for Independence for all pairs of columns 'col1', 'col2', and 'col3'\n",
        "    in the DataFrame `data_01` and return the results in `chi_square_df`.\n",
        "    \"\"\"\n",
        "\n",
        "    chi_square_results = []\n",
        "\n",
        "    for i, col1 in enumerate(categorical_columns):\n",
        "        for col2 in categorical_columns[i+1:]:\n",
        "            contingency_table = pd.crosstab(data_01[col1], data_01[col2])\n",
        "\n",
        "            chi2_stat, p_val, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "            chi_square_results.append({\n",
        "                'Column 1': col1,\n",
        "                'Column 2': col2,\n",
        "                'Chi-Square Statistic': chi2_stat,\n",
        "                'p-value': p_val,\n",
        "                'Degrees of Freedom': dof,\n",
        "                'Expected Frequencies': expected\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(chi_square_results)\n",
        "chi_square_independence(data_01, categorical_columns)"
      ],
      "metadata": {
        "id": "cnTDt2-2UiED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# independence = chi_square_independence(data_01, categorical_columns)\n",
        "# independence.to_csv('independence.csv', index=False)"
      ],
      "metadata": {
        "id": "FSIKWfnjUidp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mann_whitney_u_test_all_pairs(data_01, numeric_columns, group_column):\n",
        "    \"\"\"\n",
        "    Perform Mann-Whitney U Test between each pair of numeric variables, grouped by a categorical column.\n",
        "\n",
        "    This function calculates the Mann-Whitney U Test between all pairs of numeric variables in `numeric_columns`,\n",
        "    for each pair of groups defined by the `group_column`. It compares the distribution of each pair of numeric variables\n",
        "    between the two groups and returns the results.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    data_01 : pandas.DataFrame\n",
        "        The DataFrame containing the data. It must include numeric columns and a categorical column for grouping.\n",
        "\n",
        "    numeric_columns : list of str\n",
        "        A list of column names (strings) representing numeric columns to be tested.\n",
        "\n",
        "    group_column : str\n",
        "        The name of the categorical column used to group the data into two distinct groups for the Mann-Whitney U test.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    pandas.DataFrame\n",
        "        A DataFrame containing the results of the Mann-Whitney U Test for each pair of numeric variables.\n",
        "        The DataFrame includes the following columns:\n",
        "        - 'Numeric Variable 1': The first numeric variable in the pair.\n",
        "        - 'Numeric Variable 2': The second numeric variable in the pair.\n",
        "        - 'U-statistic': The Mann-Whitney U statistic for the test.\n",
        "        - 'p-value': The p-value for the test.\n",
        "\n",
        "    Example:\n",
        "    --------\n",
        "    mann_whitney_df = mann_whitney_u_test_all_pairs(data_01, ['col1', 'col2', 'col3'], 'group_col')\n",
        "\n",
        "    This will compute the Mann-Whitney U Test for all pairs of numeric columns ['col1', 'col2', 'col3']\n",
        "    in `data_01`, grouped by the `group_col`, and return the results in `mann_whitney_df`.\n",
        "    \"\"\"\n",
        "\n",
        "    groups = data_01[group_column[0]].dropna().unique()\n",
        "\n",
        "    mann_whitney_results = []\n",
        "\n",
        "    for i, var1 in enumerate(numeric_columns):\n",
        "        for var2 in numeric_columns[i+1:]:\n",
        "\n",
        "            group1_data_var1 = data_01[data_01[group_column[0]] == groups[0]][var1].dropna()\n",
        "            group2_data_var1 = data_01[data_01[group_column[0]] == groups[1]][var1].dropna()\n",
        "            group1_data_var2 = data_01[data_01[group_column[0]] == groups[0]][var2].dropna()\n",
        "            group2_data_var2 = data_01[data_01[group_column[0]] == groups[1]][var2].dropna()\n",
        "\n",
        "            u_stat_var1, p_val_var1 = stats.mannwhitneyu(group1_data_var1, group2_data_var1, alternative='two-sided')\n",
        "            u_stat_var2, p_val_var2 = stats.mannwhitneyu(group1_data_var2, group2_data_var2, alternative='two-sided')\n",
        "\n",
        "            mann_whitney_results.append({\n",
        "                'Numeric Variable 1': var1,\n",
        "                'Numeric Variable 2': var2,\n",
        "                'U-statistic (Var1)': u_stat_var1,\n",
        "                'p-value (Var1)': p_val_var1,\n",
        "                'U-statistic (Var2)': u_stat_var2,\n",
        "                'p-value (Var2)': p_val_var2\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(mann_whitney_results)\n",
        "\n",
        "mann_whitney_u_test_all_pairs(data_01, numerical_columns, categorical_columns)"
      ],
      "metadata": {
        "id": "oY3qaBKfUl5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mann_whitney = mann_whitney_u_test_all_pairs(data_01, numerical_columns, categorical_columns)\n",
        "# mann_whitney.to_csv('mann_whitney.csv', index=False)"
      ],
      "metadata": {
        "id": "dLcL-9apUmR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train - Test Split"
      ],
      "metadata": {
        "id": "3oClva4lUrOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "for col in categorical_cols:  # Selects only object columns\n",
        "    data_01[col] = label_encoder.fit_transform(data_01[col])"
      ],
      "metadata": {
        "id": "rU1uqPA9Uq1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numerical_cols: #Select number columns\n",
        "    data_01[col] = pd.to_numeric(data_01[col], errors='coerce')"
      ],
      "metadata": {
        "id": "P9zckDfCUuTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "data_01[numerical_cols] = scaler.fit_transform(data_01[numerical_cols])"
      ],
      "metadata": {
        "id": "mMw469sHUwKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_01.drop(['has_or_had_glasses'], axis=1)\n",
        "y = data_01['has_or_had_glasses']"
      ],
      "metadata": {
        "id": "s9hPIg4RUzao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = X.isnull().sum()\n",
        "print(\"Missing values before imputation:\\n\", missing_values[missing_values>0])"
      ],
      "metadata": {
        "id": "pHkderhdU00p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=75)"
      ],
      "metadata": {
        "id": "NFiAY8g2U2iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.concat([X_train, y_train], axis=1)\n",
        "data_test = pd.concat([X_test, y_test], axis=1)"
      ],
      "metadata": {
        "id": "b2NgcqIcU3-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.shape\n",
        "data_train.info()"
      ],
      "metadata": {
        "id": "6iAk33C1U5aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test.shape\n",
        "data_test.info()"
      ],
      "metadata": {
        "id": "NNFSEtKXU6l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.to_csv('data_train.csv', index=False)\n",
        "data_test.to_csv('data_test.csv', index=False)"
      ],
      "metadata": {
        "id": "NqwsYSJwU7s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Smote"
      ],
      "metadata": {
        "id": "uzpemCcmU9jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv('data_train.csv')\n",
        "data_test = pd.read_csv('data_test.csv')"
      ],
      "metadata": {
        "id": "MzS_U-pIU88o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_distribution = data_train['has_or_had_glasses'].value_counts()\n",
        "plt.figure(figsize=(8, 6))\n",
        "class_distribution.plot(kind='bar', color=['skyblue', 'salmon'])\n",
        "plt.title('Class Distribution of has_or_had_glasses')\n",
        "plt.xlabel('Has or Had Glasses')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h-sXP8xrVAxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_percentages = (class_distribution / len(data_train)) * 100\n",
        "print(\"Class Distribution:\")\n",
        "print(class_distribution)\n",
        "print(\"\\nClass Percentages:\")\n",
        "print(class_percentages)\n",
        "if class_percentages.min() < 30:\n",
        "    print(\"\\nConclusion: The dataset is imbalanced.\")\n",
        "else:\n",
        "    print(\"\\nConclusion: The dataset is balanced or nearly balanced.\")"
      ],
      "metadata": {
        "id": "7pMfTbX0VB_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_train.drop(['has_or_had_glasses'], axis=1)\n",
        "y = data_train['has_or_had_glasses']"
      ],
      "metadata": {
        "id": "TV0hanQhVDVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "0O3-GlAPVFCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42, k_neighbors=5)"
      ],
      "metadata": {
        "id": "fMUkVK4OVGIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "PVyFudGVVHs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_resampled_distribution = y_train_resampled.value_counts()\n",
        "y_train_resampled_percentages = (y_train_resampled_distribution / len(y_train_resampled)) * 100"
      ],
      "metadata": {
        "id": "AJzszDRJVJEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_synthetic_rows = X_train_resampled.shape[0] - X_train.shape[0]"
      ],
      "metadata": {
        "id": "-CFphjFtVLIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 2)\n",
        "y_train_resampled_distribution.plot(kind='bar', color=['skyblue', 'salmon'])\n",
        "plt.title('Resampled Training Set Class Distribution')\n",
        "plt.xlabel('Has or Had Glasses')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EPGYQnszVM-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_resampled_df = pd.DataFrame(X_train_resampled, columns=X_train.columns)\n",
        "X_train_resampled_df['has_or_had_glasses'] = y_train_resampled"
      ],
      "metadata": {
        "id": "yrGJVEuFVOb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01 = X_train_resampled_df.copy()"
      ],
      "metadata": {
        "id": "jKl3CgbjVRJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01.to_csv('data_train_main.csv', index=False)"
      ],
      "metadata": {
        "id": "Kp82tvrMVSeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stepwise Logistic Regression"
      ],
      "metadata": {
        "id": "opl94NmGVWgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv('data_train_main.csv')\n",
        "data_test = pd.read_csv('data_test.csv')"
      ],
      "metadata": {
        "id": "TVF3WNQhVTmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data_train.drop(['has_or_had_glasses'], axis=1)\n",
        "y_train = data_train['has_or_had_glasses']"
      ],
      "metadata": {
        "id": "4n8ga9Q0VYWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = data_test.drop(['has_or_had_glasses'], axis=1)\n",
        "y_test = data_test['has_or_had_glasses']"
      ],
      "metadata": {
        "id": "vTsRZzHjVZjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)"
      ],
      "metadata": {
        "id": "Xfo4eDjrVav4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "UXrTH5HtVb59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_copy = X_train.copy()\n",
        "y_train_copy = y_train.copy()"
      ],
      "metadata": {
        "id": "b9FUpFXtVdOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sfs = SFS(LogisticRegression(solver='liblinear', penalty='l1'),  # Add L1 regularization\n",
        "          k_features=10,\n",
        "          forward=True,\n",
        "          floating=True,\n",
        "          scoring='accuracy',\n",
        "          cv=5,\n",
        "          n_jobs=-1)"
      ],
      "metadata": {
        "id": "xBkLc8kCVeTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sfs = sfs.fit(X_train_copy, y_train_copy)"
      ],
      "metadata": {
        "id": "aIxifHKfVgDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = list(sfs.k_feature_names_)\n",
        "print(\"Selected features:\", selected_features)"
      ],
      "metadata": {
        "id": "40iykhscVh0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "ZQAn5U8HVovJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_selected = X_train_copy[selected_features]"
      ],
      "metadata": {
        "id": "H1czfGAXVmq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_selected_with_constant = sm.add_constant(X_train_selected)"
      ],
      "metadata": {
        "id": "xpqhNHKxVrmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit_model = sm.Logit(y_train_copy, X_train_selected_with_constant).fit_regularized(method='l1')"
      ],
      "metadata": {
        "id": "XcNoBZbtVtNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(logit_model.summary())"
      ],
      "metadata": {
        "id": "DKI6HQx7VuhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "ranked_features = {\n",
        "    'reading_hours': 17.709124,\n",
        "    'dark_usage': 2.341641,\n",
        "    'age': 1.497100,\n",
        "    'sleep_hours': 1.258598,\n",
        "    'screen_hours': 0.659592,\n",
        "    'occupation': 0.521482,\n",
        "    'sunlight_hours': 0.448405,\n",
        "    'lighting_conditions': 0.399558,\n",
        "    'outdoor_activity': 0.201879,\n",
        "    'exercise_frequency': 0.144893,\n",
        "    'education': 0.070323\n",
        "}\n",
        "\n",
        "data = {'variable': list(ranked_features.keys()), 'importance': list(ranked_features.values())}\n",
        "\n",
        "fig = px.pie(data, names='variable', values='importance',\n",
        "             title='Updated Variable Contribution to Glasses Prediction',\n",
        "             hover_data=['importance'],\n",
        "             labels={'importance': 'Relative Importance'},\n",
        "             color_discrete_sequence=px.colors.qualitative.Pastel,\n",
        "             width=800,\n",
        "             height=800)\n",
        "\n",
        "fig.update_traces(textinfo='percent+label', pull=[0.03]*len(ranked_features))\n",
        "fig.update_layout(title_font_size=20, title_x=0.5, uniformtext_minsize=12, uniformtext_mode='hide')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "mcdZufk3Vvt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assumption"
      ],
      "metadata": {
        "id": "EbZb7XyPWe0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n1. Binary Outcome:\")\n",
        "print(\"The target variable has values:\", y_train.unique())\n",
        "if len(y_train.unique()) == 2:\n",
        "    print(\"Assumption met: The outcome is binary (0 and 1).\")\n",
        "else:\n",
        "    print(\"Assumption NOT met: The outcome is not binary.\")"
      ],
      "metadata": {
        "id": "ngQiUNFHV7Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n2. Independence of Observations:\")"
      ],
      "metadata": {
        "id": "9Wiych7eWhHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n3. Multicollinearity\")\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = X_train_selected_with_constant.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_train_selected_with_constant.values, i)\n",
        "                   for i in range(X_train_selected_with_constant.shape[1])]\n",
        "print(vif_data)"
      ],
      "metadata": {
        "id": "jXR-JG28WiZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank = np.linalg.matrix_rank(X_train_selected_with_constant)\n",
        "print(f\"Matrix rank: {rank}, Columns: {X_train_selected_with_constant.shape[1]}\")"
      ],
      "metadata": {
        "id": "CL0QaCL_Wjz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients = logit_model.params\n",
        "p_values = logit_model.pvalues"
      ],
      "metadata": {
        "id": "rXcYWl57HrTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_features = abs(coefficients).sort_values(ascending=False)\n",
        "print(\"\\nRanked Features by Absolute Coefficient Value:\")\n",
        "print(ranked_features)"
      ],
      "metadata": {
        "id": "5KZQIznKHmje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "cJBSWDmsWote"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv('data_train_main.csv')\n",
        "data_test = pd.read_csv('data_test.csv')"
      ],
      "metadata": {
        "id": "RF5gzj9UrzDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data_train.drop(['has_or_had_glasses'], axis=1)\n",
        "y_train = data_train['has_or_had_glasses']"
      ],
      "metadata": {
        "id": "8_sGD-BdrzDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = data_test.drop(['has_or_had_glasses'], axis=1)\n",
        "y_test = data_test['has_or_had_glasses']"
      ],
      "metadata": {
        "id": "i8SdVfvjrzDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[selected_features]\n",
        "X_test = X_test[selected_features]"
      ],
      "metadata": {
        "id": "7isUqwtWWlpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "ZpJZP1Q5WqR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "    loss=keras.losses.BinaryCrossentropy(label_smoothing=0.1),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "Q6vsFZn0WrZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "fp9lNWqKWsvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "y_test = y_test.astype('float32')"
      ],
      "metadata": {
        "id": "Axfl4_wPWuGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "9FZVU_Y-WvaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "0KFndEk2WxEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "gBXukILgWz1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs = model.predict(X_test)"
      ],
      "metadata": {
        "id": "BBZh3wC_W9YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (y_pred_probs > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "4KyddFH-W-wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logloss = log_loss(y_test, y_pred_probs)"
      ],
      "metadata": {
        "id": "5_NNHSreXATn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.get_weights()"
      ],
      "metadata": {
        "id": "NUOwfBeVXF3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_layer_weights = weights[0]"
      ],
      "metadata": {
        "id": "HnnJ23RsXHjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_coefficients = np.abs(first_layer_weights).sum(axis=1)"
      ],
      "metadata": {
        "id": "sro57_kwXJZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = X_train.columns\n",
        "for name, coef in zip(feature_names, nn_coefficients):\n",
        "    print(f\"{name}: {coef:.4f}\")"
      ],
      "metadata": {
        "id": "slfnH0bRXNE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Neural Network Test Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "dFZnqt49X1qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Log Loss (Calibration Check): {logloss:.4f}')"
      ],
      "metadata": {
        "id": "OGvEry_mX8R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "-hU4_RTjX9pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix:\")\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "anLvvMHfX_MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)"
      ],
      "metadata": {
        "id": "ww0XgW6CYAXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Print the AUC score\n",
        "print(f\"AUC Score: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "id": "cZ4LCgriYBZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.barh(feature_names, nn_coefficients)\n",
        "plt.xlabel(\"Importance (|weight sum|)\")\n",
        "plt.title(\"Feature Importance (NN)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FCgxcaC8YEzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The End\")"
      ],
      "metadata": {
        "id": "FBxXYGw0fchf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}